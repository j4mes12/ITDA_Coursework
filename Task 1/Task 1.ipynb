{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction\n",
    "### code from `data_loader_demo.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "annoying-ethiopia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Use HuggingFace's datasets library to access the financial_phrasebank dataset\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Exploration\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Feature Engineering\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Modelling\n",
    "import params as p\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, roc_auc_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import optuna\n",
    "from optuna.integration import XGBoostPruningCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f4a2e7-8a1f-4fed-a323-1b82d7080e03",
   "metadata": {},
   "source": [
    "# Financial Phrasebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8502fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset financial_phrasebank (/Users/jamesstephenson/.cache/huggingface/datasets/financial_phrasebank/sentences_50agree/1.0.0/a6d468761d4e0c8ae215c77367e1092bead39deb08fbf4bffd7c0a6991febbf0)\n",
      "100%|██████████| 1/1 [00:00<00:00, 53.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is a dictionary with two splits: \n",
      "\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label'],\n",
      "        num_rows: 4846\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# The financial_phrasebank dataset is available in four variations. It has no predefined train/validation/test splits.\n",
    "# Each data point was annotated by 5-8 people, then their annotations were combined. \n",
    "# Each variation of the dataset contains examples with different levels of agreement. \n",
    "# Let's use the one containing all data points where at least 50% of the annotators agreed on the label.\n",
    "dataset = load_dataset(\n",
    "    \"financial_phrasebank\", \n",
    "    'sentences_50agree' # Select variation of the dataset\n",
    ")\n",
    "\n",
    "print(f'The dataset is a dictionary with two splits: \\n\\n{dataset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca009bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split test data from training data\n",
    "train_sentences, test_sentences, train_labels, test_labels = train_test_split(\n",
    "    dataset[\"train\"]['sentence'], \n",
    "    dataset[\"train\"]['label'], \n",
    "    test_size=0.2, \n",
    "    stratify=dataset[\"train\"]['label']  # make sure the same proportion of labels is in the test set and training set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b3af369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many instances in the train dataset? \n",
      "\n",
      "3876\n",
      "\n",
      "What does one instance look like? \n",
      "\n",
      "The company is headquartered in Sievi , Finland , and is listed on the Nordic Exchange in Helsinki .\n"
     ]
    }
   ],
   "source": [
    "# label 0 = negative, 1 = neutral, 2 = positive\n",
    "print(f'How many instances in the train dataset? \\n\\n{len(train_sentences)}')\n",
    "print('')\n",
    "print(f'What does one instance look like? \\n\\n{train_sentences[234]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58ea906-8488-43a9-90dd-94695d700d19",
   "metadata": {},
   "source": [
    "It may also be necessary to create a _validation_ set (also called 'development' set or 'devset'). The validation set can be used to compute performance of your model when tuning hyperparameters,  optimising combinations of features, or looking at the errors your model makes before improving it. This allows you to hold out the test set to give a fair evaluation of the model and how well it generalises to new examples. This avoids tuning the model to specifso it gets good performance on the test set examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c873dbe-b6a6-41ed-9f03-b52a5e0a85c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_sentences, train_labels, test_size=0.25, stratify=train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57d10fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many instances in the validation dataset? \n",
      "\n",
      "969\n",
      "\n",
      "How many instances in the test dataset? \n",
      "\n",
      "970\n"
     ]
    }
   ],
   "source": [
    "print(f'How many instances in the validation dataset? \\n\\n{len(val_sentences)}\\n')\n",
    "print(f'How many instances in the test dataset? \\n\\n{len(test_sentences)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame({'sentences' : train_sentences, 'labels' : train_labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Very Brief Response Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should only need to do this for train due to random split. So would expect to see the same structure for test and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (15, 8))\n",
    "\n",
    "ax = train.labels.value_counts().plot(kind='bar', title = 'Label Counts')\n",
    "\n",
    "ax.set_xlabel(\"Labels\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "plt.xticks(rotation = 0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slight Imbalance of labels, but nothing that will be an issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featuring Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove some stopwords to capture negation in n-grams if possible\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words.remove('no')\n",
    "stop_words.remove('not')\n",
    "stop_words.remove('but')\n",
    "\n",
    "# load up a simple porter stemmer - nothing fancy\n",
    "ps = nltk.porter.PorterStemmer()\n",
    "\n",
    "def simple_text_preprocessor(document): \n",
    "    # lower case\n",
    "    document = str(document).lower()\n",
    "    \n",
    "    # remove unnecessary characters\n",
    "    document = re.sub(r'[^a-zA-Z]',r' ', document)\n",
    "    document = re.sub(r'nbsp', r'', document)\n",
    "    document = re.sub(' +', ' ', document)\n",
    "    \n",
    "    # simple porter stemming\n",
    "    document = ' '.join([ps.stem(word) for word in document.split()])\n",
    "    \n",
    "    # stopwords removal\n",
    "    document = ' '.join([word for word in document.split() if word not in stop_words])\n",
    "    \n",
    "    return document\n",
    "\n",
    "stp = np.vectorize(simple_text_preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_sentences = stp(train_sentences)\n",
    "clean_test_sentences = stp(test_sentences)\n",
    "clean_val_sentences = stp(val_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df = 0.0, max_df = 1.0, ngram_range = (1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tfidf.fit_transform(clean_train_sentences).toarray()\n",
    "X_train = pd.DataFrame(X_train, columns = tfidf.get_feature_names_out())\n",
    "\n",
    "X_test = tfidf.transform(clean_test_sentences).toarray()\n",
    "X_test = pd.DataFrame(X_test, columns = tfidf.get_feature_names_out())\n",
    "\n",
    "X_val = tfidf.transform(clean_val_sentences).toarray()\n",
    "X_val = pd.DataFrame(X_val, columns = tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaland</th>\n",
       "      <th>aaland island</th>\n",
       "      <th>aalborg</th>\n",
       "      <th>aalborg northern</th>\n",
       "      <th>aava</th>\n",
       "      <th>aava mobil</th>\n",
       "      <th>ab</th>\n",
       "      <th>ab acanb</th>\n",
       "      <th>ab crown</th>\n",
       "      <th>ab finnish</th>\n",
       "      <th>...</th>\n",
       "      <th>zoltan krippl</th>\n",
       "      <th>zone</th>\n",
       "      <th>zone plan</th>\n",
       "      <th>zone villag</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoo poland</th>\n",
       "      <th>zte</th>\n",
       "      <th>zte corp</th>\n",
       "      <th>zu</th>\n",
       "      <th>zu beeinflussen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29407 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaland  aaland island  aalborg  aalborg northern  aava  aava mobil   ab  \\\n",
       "0     0.0            0.0      0.0               0.0   0.0         0.0  0.0   \n",
       "1     0.0            0.0      0.0               0.0   0.0         0.0  0.0   \n",
       "2     0.0            0.0      0.0               0.0   0.0         0.0  0.0   \n",
       "3     0.0            0.0      0.0               0.0   0.0         0.0  0.0   \n",
       "4     0.0            0.0      0.0               0.0   0.0         0.0  0.0   \n",
       "\n",
       "   ab acanb  ab crown  ab finnish  ...  zoltan krippl  zone  zone plan  \\\n",
       "0       0.0       0.0         0.0  ...            0.0   0.0        0.0   \n",
       "1       0.0       0.0         0.0  ...            0.0   0.0        0.0   \n",
       "2       0.0       0.0         0.0  ...            0.0   0.0        0.0   \n",
       "3       0.0       0.0         0.0  ...            0.0   0.0        0.0   \n",
       "4       0.0       0.0         0.0  ...            0.0   0.0        0.0   \n",
       "\n",
       "   zone villag  zoo  zoo poland  zte  zte corp   zu  zu beeinflussen  \n",
       "0          0.0  0.0         0.0  0.0       0.0  0.0              0.0  \n",
       "1          0.0  0.0         0.0  0.0       0.0  0.0              0.0  \n",
       "2          0.0  0.0         0.0  0.0       0.0  0.0              0.0  \n",
       "3          0.0  0.0         0.0  0.0       0.0  0.0              0.0  \n",
       "4          0.0  0.0         0.0  0.0       0.0  0.0              0.0  \n",
       "\n",
       "[5 rows x 29407 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_labels\n",
    "y_test = test_labels\n",
    "y_val = val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {'X' : X_train, 'y' : y_train}\n",
    "test_data = {'X' : X_test, 'y' : y_test}\n",
    "val_data = {'X' : X_val, 'y' : y_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred_probs = model.predict_proba(X)\n",
    "\n",
    "    print('ROC AUC Score:\\t', roc_auc_score(y, y_pred_probs, average = 'macro', multi_class='ovr'))\n",
    "\n",
    "    print('--- MACRO ---')\n",
    "    print(f'Accuracy:\\t', accuracy_score(y, y_pred))\n",
    "    print(f'Precision:\\t', precision_score(y, y_pred, average='macro'))\n",
    "    print(f'Recall:\\t\\t', recall_score(y, y_pred, average='macro'))\n",
    "    print(f'F1 score:\\t', f1_score(y, y_pred, average='macro'))\n",
    "\n",
    "    # We can get all of these with a per-class breakdown using classification_report:\n",
    "    print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB().fit(**train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score:\t 0.8064821047757649\n",
      "--- MACRO ---\n",
      "Accuracy:\t 0.654639175257732\n",
      "Precision:\t 0.7483145339037988\n",
      "Recall:\t\t 0.41882218160627255\n",
      "F1 score:\t 0.4004735218751297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.04      0.08       121\n",
      "           1       0.66      0.98      0.79       576\n",
      "           2       0.58      0.23      0.33       273\n",
      "\n",
      "    accuracy                           0.65       970\n",
      "   macro avg       0.75      0.42      0.40       970\n",
      "weighted avg       0.68      0.65      0.57       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(nb, **test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:01:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(random_state = p.RANDOM_STATE).fit(**train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score:\t 0.855167658141454\n",
      "--- MACRO ---\n",
      "Accuracy:\t 0.7381443298969073\n",
      "Precision:\t 0.7137313432835821\n",
      "Recall:\t\t 0.6540325205097932\n",
      "F1 score:\t 0.6757188665610251\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.58      0.63       121\n",
      "           1       0.76      0.89      0.82       576\n",
      "           2       0.68      0.50      0.58       273\n",
      "\n",
      "    accuracy                           0.74       970\n",
      "   macro avg       0.71      0.65      0.68       970\n",
      "weighted avg       0.73      0.74      0.73       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(xgb, **test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-25 17:06:53,269]\u001b[0m A new study created in memory with name: no-name-7ac4b304-521f-4b0e-8ae4-e5a4e53da606\u001b[0m\n",
      "/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[33m[W 2022-03-25 17:07:35,060]\u001b[0m Trial 0 failed because of the following error: XGBoostError('[17:07:34] ../src/metric/elementwise_metric.cu:365: Check failed: preds.Size() == info.labels_.Size() (8721 vs. 2907) : label and prediction size not match, hint: use merror or mlogloss for multi-class classification\\nStack trace:\\n  [bt] (0) 1   libxgboost.dylib                    0x0000000175dcba54 dmlc::LogMessageFatal::~LogMessageFatal() + 116\\n  [bt] (1) 2   libxgboost.dylib                    0x0000000175ea4c1a xgboost::metric::EvalEWiseBase<xgboost::metric::EvalRowRMSE>::Eval(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, bool) + 298\\n  [bt] (2) 3   libxgboost.dylib                    0x0000000175e7cc03 xgboost::LearnerImpl::EvalOneIter(int, std::__1::vector<std::__1::shared_ptr<xgboost::DMatrix>, std::__1::allocator<std::__1::shared_ptr<xgboost::DMatrix> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) + 2371\\n  [bt] (3) 4   libxgboost.dylib                    0x0000000175dd0792 XGBoosterEvalOneIter + 578\\n  [bt] (4) 5   libffi.8.dylib                      0x000000010a1b8d92 ffi_call_unix64 + 82\\n  [bt] (5) 6   ???                                 0x000000030fa125d0 0x0 + 13147121104\\n\\n')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/2f/cwgmhyzx4fn5cwp5j_dpmsd00000gn/T/ipykernel_22550/4276141754.py\", line 23, in xgb_objective\n",
      "    xgb_obj.fit(\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py\", line 82, in _train_internal\n",
      "    if callbacks.after_iteration(bst, i, dtrain, evals):\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/callback.py\", line 434, in after_iteration\n",
      "    score = model.eval_set(evals, epoch, self.metric)\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py\", line 1744, in eval_set\n",
      "    _check_call(_LIB.XGBoosterEvalOneIter(self.handle,\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [17:07:34] ../src/metric/elementwise_metric.cu:365: Check failed: preds.Size() == info.labels_.Size() (8721 vs. 2907) : label and prediction size not match, hint: use merror or mlogloss for multi-class classification\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000175dcba54 dmlc::LogMessageFatal::~LogMessageFatal() + 116\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x0000000175ea4c1a xgboost::metric::EvalEWiseBase<xgboost::metric::EvalRowRMSE>::Eval(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, bool) + 298\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x0000000175e7cc03 xgboost::LearnerImpl::EvalOneIter(int, std::__1::vector<std::__1::shared_ptr<xgboost::DMatrix>, std::__1::allocator<std::__1::shared_ptr<xgboost::DMatrix> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) + 2371\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x0000000175dd0792 XGBoosterEvalOneIter + 578\n",
      "  [bt] (4) 5   libffi.8.dylib                      0x000000010a1b8d92 ffi_call_unix64 + 82\n",
      "  [bt] (5) 6   ???                                 0x000000030fa125d0 0x0 + 13147121104\n",
      "\n",
      "\n",
      "\u001b[33m[W 2022-03-25 17:10:22,752]\u001b[0m Trial 2 failed because of the following error: XGBoostError('[17:10:22] ../src/metric/elementwise_metric.cu:365: Check failed: preds.Size() == info.labels_.Size() (8721 vs. 2907) : label and prediction size not match, hint: use merror or mlogloss for multi-class classification\\nStack trace:\\n  [bt] (0) 1   libxgboost.dylib                    0x0000000175dcba54 dmlc::LogMessageFatal::~LogMessageFatal() + 116\\n  [bt] (1) 2   libxgboost.dylib                    0x0000000175ea4c1a xgboost::metric::EvalEWiseBase<xgboost::metric::EvalRowRMSE>::Eval(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, bool) + 298\\n  [bt] (2) 3   libxgboost.dylib                    0x0000000175e7cc03 xgboost::LearnerImpl::EvalOneIter(int, std::__1::vector<std::__1::shared_ptr<xgboost::DMatrix>, std::__1::allocator<std::__1::shared_ptr<xgboost::DMatrix> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) + 2371\\n  [bt] (3) 4   libxgboost.dylib                    0x0000000175dd0792 XGBoosterEvalOneIter + 578\\n  [bt] (4) 5   libffi.8.dylib                      0x000000010a1b8d92 ffi_call_unix64 + 82\\n  [bt] (5) 6   ???                                 0x0000000311a185d0 0x0 + 13180700112\\n\\n')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/2f/cwgmhyzx4fn5cwp5j_dpmsd00000gn/T/ipykernel_22550/4276141754.py\", line 23, in xgb_objective\n",
      "    xgb_obj.fit(\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py\", line 82, in _train_internal\n",
      "    if callbacks.after_iteration(bst, i, dtrain, evals):\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/callback.py\", line 434, in after_iteration\n",
      "    score = model.eval_set(evals, epoch, self.metric)\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py\", line 1744, in eval_set\n",
      "    _check_call(_LIB.XGBoosterEvalOneIter(self.handle,\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [17:10:22] ../src/metric/elementwise_metric.cu:365: Check failed: preds.Size() == info.labels_.Size() (8721 vs. 2907) : label and prediction size not match, hint: use merror or mlogloss for multi-class classification\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000175dcba54 dmlc::LogMessageFatal::~LogMessageFatal() + 116\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x0000000175ea4c1a xgboost::metric::EvalEWiseBase<xgboost::metric::EvalRowRMSE>::Eval(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, bool) + 298\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x0000000175e7cc03 xgboost::LearnerImpl::EvalOneIter(int, std::__1::vector<std::__1::shared_ptr<xgboost::DMatrix>, std::__1::allocator<std::__1::shared_ptr<xgboost::DMatrix> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) + 2371\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x0000000175dd0792 XGBoosterEvalOneIter + 578\n",
      "  [bt] (4) 5   libffi.8.dylib                      0x000000010a1b8d92 ffi_call_unix64 + 82\n",
      "  [bt] (5) 6   ???                                 0x0000000311a185d0 0x0 + 13180700112\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py:106\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=104'>105</a>\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m completed:\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=105'>106</a>\u001b[0m         f\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=107'>108</a>\u001b[0m futures\u001b[39m.\u001b[39madd(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=108'>109</a>\u001b[0m     executor\u001b[39m.\u001b[39msubmit(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=109'>110</a>\u001b[0m         _optimize_sequential,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=120'>121</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=121'>122</a>\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data_analytics/lib/python3.9/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/concurrent/futures/_base.py?line=437'>438</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/concurrent/futures/_base.py?line=438'>439</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/concurrent/futures/_base.py?line=440'>441</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data_analytics/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/concurrent/futures/_base.py?line=389'>390</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/concurrent/futures/_base.py?line=390'>391</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/concurrent/futures/_base.py?line=391'>392</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/concurrent/futures/_base.py?line=392'>393</a>\u001b[0m     \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data_analytics/lib/python3.9/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/concurrent/futures/thread.py?line=56'>57</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/concurrent/futures/thread.py?line=57'>58</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/concurrent/futures/thread.py?line=58'>59</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=161'>162</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=162'>163</a>\u001b[0m     trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=163'>164</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py:264\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=262'>263</a>\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch):\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=263'>264</a>\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=264'>265</a>\u001b[0m \u001b[39mreturn\u001b[39;00m trial\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py:213\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=211'>212</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=212'>213</a>\u001b[0m     value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=213'>214</a>\u001b[0m \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=214'>215</a>\u001b[0m     \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n",
      "\u001b[1;32m/Users/jamesstephenson/Documents/University:Work/Data Science MSc/ITDA/Coursework/ITDA_Coursework/Task 1/Task 1.ipynb Cell 34'\u001b[0m in \u001b[0;36mxgb_objective\u001b[0;34m(trial, X_train, y_train, X_test, y_test, base_params)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jamesstephenson/Documents/University%3AWork/Data%20Science%20MSc/ITDA/Coursework/ITDA_Coursework/Task%201/Task%201.ipynb#ch0000039?line=21'>22</a>\u001b[0m xgb_obj \u001b[39m=\u001b[39m XGBClassifier(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mobj_params)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jamesstephenson/Documents/University%3AWork/Data%20Science%20MSc/ITDA/Coursework/ITDA_Coursework/Task%201/Task%201.ipynb#ch0000039?line=22'>23</a>\u001b[0m xgb_obj\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jamesstephenson/Documents/University%3AWork/Data%20Science%20MSc/ITDA/Coursework/ITDA_Coursework/Task%201/Task%201.ipynb#ch0000039?line=23'>24</a>\u001b[0m     X_train,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jamesstephenson/Documents/University%3AWork/Data%20Science%20MSc/ITDA/Coursework/ITDA_Coursework/Task%201/Task%201.ipynb#ch0000039?line=24'>25</a>\u001b[0m     y_train,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jamesstephenson/Documents/University%3AWork/Data%20Science%20MSc/ITDA/Coursework/ITDA_Coursework/Task%201/Task%201.ipynb#ch0000039?line=25'>26</a>\u001b[0m     eval_metric \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mrmse\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jamesstephenson/Documents/University%3AWork/Data%20Science%20MSc/ITDA/Coursework/ITDA_Coursework/Task%201/Task%201.ipynb#ch0000039?line=26'>27</a>\u001b[0m     eval_set \u001b[39m=\u001b[39;49m [(X_train, y_train), (X_test, y_test)],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jamesstephenson/Documents/University%3AWork/Data%20Science%20MSc/ITDA/Coursework/ITDA_Coursework/Task%201/Task%201.ipynb#ch0000039?line=27'>28</a>\u001b[0m     early_stopping_rounds \u001b[39m=\u001b[39;49m obj_params[\u001b[39m'\u001b[39;49m\u001b[39mn_estimators\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m*\u001b[39;49m \u001b[39m0.1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jamesstephenson/Documents/University%3AWork/Data%20Science%20MSc/ITDA/Coursework/ITDA_Coursework/Task%201/Task%201.ipynb#ch0000039?line=28'>29</a>\u001b[0m     verbose \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jamesstephenson/Documents/University%3AWork/Data%20Science%20MSc/ITDA/Coursework/ITDA_Coursework/Task%201/Task%201.ipynb#ch0000039?line=29'>30</a>\u001b[0m     callbacks \u001b[39m=\u001b[39;49m [pruning_callback]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jamesstephenson/Documents/University%3AWork/Data%20Science%20MSc/ITDA/Coursework/ITDA_Coursework/Task%201/Task%201.ipynb#ch0000039?line=30'>31</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jamesstephenson/Documents/University%3AWork/Data%20Science%20MSc/ITDA/Coursework/ITDA_Coursework/Task%201/Task%201.ipynb#ch0000039?line=32'>33</a>\u001b[0m y_pred \u001b[39m=\u001b[39m xgb_obj\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py:506\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py?line=504'>505</a>\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py?line=505'>506</a>\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py:1250\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py?line=1230'>1231</a>\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py?line=1231'>1232</a>\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py?line=1232'>1233</a>\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py?line=1246'>1247</a>\u001b[0m     label_transform\u001b[39m=\u001b[39mlabel_transform,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py?line=1247'>1248</a>\u001b[0m )\n\u001b[0;32m-> <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py?line=1249'>1250</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py?line=1250'>1251</a>\u001b[0m     params,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py?line=1251'>1252</a>\u001b[0m     train_dmatrix,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py?line=1252'>1253</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py?line=1253'>1254</a>\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py?line=1254'>1255</a>\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py?line=1255'>1256</a>\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py?line=1256'>1257</a>\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py?line=1257'>1258</a>\u001b[0m     feval\u001b[39m=\u001b[39;49mfeval,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py?line=1258'>1259</a>\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py?line=1259'>1260</a>\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py?line=1260'>1261</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py?line=1261'>1262</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py?line=1263'>1264</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py:188\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py?line=118'>119</a>\u001b[0m \u001b[39m\"\"\"Train a booster with given parameters.\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py?line=119'>120</a>\u001b[0m \n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py?line=120'>121</a>\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py?line=185'>186</a>\u001b[0m \u001b[39mBooster : a trained booster model\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py?line=186'>187</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py?line=187'>188</a>\u001b[0m bst \u001b[39m=\u001b[39m _train_internal(params, dtrain,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py?line=188'>189</a>\u001b[0m                       num_boost_round\u001b[39m=\u001b[39;49mnum_boost_round,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py?line=189'>190</a>\u001b[0m                       evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py?line=190'>191</a>\u001b[0m                       obj\u001b[39m=\u001b[39;49mobj, feval\u001b[39m=\u001b[39;49mfeval,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py?line=191'>192</a>\u001b[0m                       xgb_model\u001b[39m=\u001b[39;49mxgb_model, callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py?line=192'>193</a>\u001b[0m                       verbose_eval\u001b[39m=\u001b[39;49mverbose_eval,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py?line=193'>194</a>\u001b[0m                       evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py?line=194'>195</a>\u001b[0m                       maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py?line=195'>196</a>\u001b[0m                       early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py?line=196'>197</a>\u001b[0m \u001b[39mreturn\u001b[39;00m bst\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py:82\u001b[0m, in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py?line=80'>81</a>\u001b[0m bst\u001b[39m.\u001b[39mupdate(dtrain, i, obj)\n\u001b[0;32m---> <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py?line=81'>82</a>\u001b[0m \u001b[39mif\u001b[39;00m callbacks\u001b[39m.\u001b[39;49mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m     <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py?line=82'>83</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/callback.py:434\u001b[0m, in \u001b[0;36mCallbackContainer.after_iteration\u001b[0;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/callback.py?line=432'>433</a>\u001b[0m     \u001b[39massert\u001b[39;00m name\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mDataset name should not contain `-`\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/callback.py?line=433'>434</a>\u001b[0m score \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49meval_set(evals, epoch, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetric)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/callback.py?line=434'>435</a>\u001b[0m score \u001b[39m=\u001b[39m score\u001b[39m.\u001b[39msplit()[\u001b[39m1\u001b[39m:]  \u001b[39m# into datasets\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py:1744\u001b[0m, in \u001b[0;36mBooster.eval_set\u001b[0;34m(self, evals, iteration, feval)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py?line=1742'>1743</a>\u001b[0m msg \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_char_p()\n\u001b[0;32m-> <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py?line=1743'>1744</a>\u001b[0m _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterEvalOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py?line=1744'>1745</a>\u001b[0m                                       ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py?line=1745'>1746</a>\u001b[0m                                       dmats, evnames,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py?line=1746'>1747</a>\u001b[0m                                       c_bst_ulong(\u001b[39mlen\u001b[39;49m(evals)),\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py?line=1747'>1748</a>\u001b[0m                                       ctypes\u001b[39m.\u001b[39;49mbyref(msg)))\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py?line=1748'>1749</a>\u001b[0m res \u001b[39m=\u001b[39m msg\u001b[39m.\u001b[39mvalue\u001b[39m.\u001b[39mdecode()  \u001b[39m# pylint: disable=no-member\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py:218\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py?line=216'>217</a>\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py?line=217'>218</a>\u001b[0m     \u001b[39mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[39m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [17:07:34] ../src/metric/elementwise_metric.cu:365: Check failed: preds.Size() == info.labels_.Size() (8721 vs. 2907) : label and prediction size not match, hint: use merror or mlogloss for multi-class classification\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x0000000175dcba54 dmlc::LogMessageFatal::~LogMessageFatal() + 116\n  [bt] (1) 2   libxgboost.dylib                    0x0000000175ea4c1a xgboost::metric::EvalEWiseBase<xgboost::metric::EvalRowRMSE>::Eval(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, bool) + 298\n  [bt] (2) 3   libxgboost.dylib                    0x0000000175e7cc03 xgboost::LearnerImpl::EvalOneIter(int, std::__1::vector<std::__1::shared_ptr<xgboost::DMatrix>, std::__1::allocator<std::__1::shared_ptr<xgboost::DMatrix> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) + 2371\n  [bt] (3) 4   libxgboost.dylib                    0x0000000175dd0792 XGBoosterEvalOneIter + 578\n  [bt] (4) 5   libffi.8.dylib                      0x000000010a1b8d92 ffi_call_unix64 + 82\n  [bt] (5) 6   ???                                 0x000000030fa125d0 0x0 + 13147121104\n\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jamesstephenson/Documents/University:Work/Data Science MSc/ITDA/Coursework/ITDA_Coursework/Task 1/Task 1.ipynb Cell 34'\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jamesstephenson/Documents/University%3AWork/Data%20Science%20MSc/ITDA/Coursework/ITDA_Coursework/Task%201/Task%201.ipynb#ch0000039?line=36'>37</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m roc\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jamesstephenson/Documents/University%3AWork/Data%20Science%20MSc/ITDA/Coursework/ITDA_Coursework/Task%201/Task%201.ipynb#ch0000039?line=38'>39</a>\u001b[0m xgb_study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jamesstephenson/Documents/University%3AWork/Data%20Science%20MSc/ITDA/Coursework/ITDA_Coursework/Task%201/Task%201.ipynb#ch0000039?line=39'>40</a>\u001b[0m xgb_study\u001b[39m.\u001b[39;49moptimize(xgb_objective, n_trials \u001b[39m=\u001b[39;49m \u001b[39m200\u001b[39;49m, n_jobs \u001b[39m=\u001b[39;49m \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/study.py:400\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/study.py?line=391'>392</a>\u001b[0m \u001b[39mif\u001b[39;00m n_jobs \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/study.py?line=392'>393</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/study.py?line=393'>394</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`n_jobs` argument has been deprecated in v2.7.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/study.py?line=394'>395</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis feature will be removed in v4.0.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/study.py?line=395'>396</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSee https://github.com/optuna/optuna/releases/tag/v2.7.0.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/study.py?line=396'>397</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/study.py?line=397'>398</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/study.py?line=399'>400</a>\u001b[0m _optimize(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/study.py?line=400'>401</a>\u001b[0m     study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/study.py?line=401'>402</a>\u001b[0m     func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/study.py?line=402'>403</a>\u001b[0m     n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/study.py?line=403'>404</a>\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/study.py?line=404'>405</a>\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/study.py?line=405'>406</a>\u001b[0m     catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/study.py?line=406'>407</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/study.py?line=407'>408</a>\u001b[0m     gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/study.py?line=408'>409</a>\u001b[0m     show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/study.py?line=409'>410</a>\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py:108\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=104'>105</a>\u001b[0m                     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m completed:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=105'>106</a>\u001b[0m                         f\u001b[39m.\u001b[39mresult()\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=107'>108</a>\u001b[0m                 futures\u001b[39m.\u001b[39madd(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=108'>109</a>\u001b[0m                     executor\u001b[39m.\u001b[39msubmit(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=109'>110</a>\u001b[0m                         _optimize_sequential,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=110'>111</a>\u001b[0m                         study,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=111'>112</a>\u001b[0m                         func,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=112'>113</a>\u001b[0m                         \u001b[39m1\u001b[39m,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=113'>114</a>\u001b[0m                         timeout,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=114'>115</a>\u001b[0m                         catch,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=115'>116</a>\u001b[0m                         callbacks,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=116'>117</a>\u001b[0m                         gc_after_trial,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=117'>118</a>\u001b[0m                         \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=118'>119</a>\u001b[0m                         time_start,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=119'>120</a>\u001b[0m                         \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=120'>121</a>\u001b[0m                     )\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=121'>122</a>\u001b[0m                 )\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=122'>123</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py?line=123'>124</a>\u001b[0m     study\u001b[39m.\u001b[39m_optimize_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data_analytics/lib/python3.9/concurrent/futures/_base.py:637\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/concurrent/futures/_base.py?line=635'>636</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/concurrent/futures/_base.py?line=636'>637</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshutdown(wait\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/concurrent/futures/_base.py?line=637'>638</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data_analytics/lib/python3.9/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/concurrent/futures/thread.py?line=232'>233</a>\u001b[0m \u001b[39mif\u001b[39;00m wait:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/concurrent/futures/thread.py?line=233'>234</a>\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads:\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/concurrent/futures/thread.py?line=234'>235</a>\u001b[0m         t\u001b[39m.\u001b[39;49mjoin()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data_analytics/lib/python3.9/threading.py:1053\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/threading.py?line=1049'>1050</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/threading.py?line=1051'>1052</a>\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/threading.py?line=1052'>1053</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/threading.py?line=1053'>1054</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/threading.py?line=1054'>1055</a>\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/threading.py?line=1055'>1056</a>\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/threading.py?line=1056'>1057</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data_analytics/lib/python3.9/threading.py:1073\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/threading.py?line=1069'>1070</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/threading.py?line=1071'>1072</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/threading.py?line=1072'>1073</a>\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/threading.py?line=1073'>1074</a>\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/data_analytics/lib/python3.9/threading.py?line=1074'>1075</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2022-03-25 17:14:56,704]\u001b[0m Trial 6 failed because of the following error: XGBoostError('[17:14:55] ../src/metric/elementwise_metric.cu:365: Check failed: preds.Size() == info.labels_.Size() (8721 vs. 2907) : label and prediction size not match, hint: use merror or mlogloss for multi-class classification\\nStack trace:\\n  [bt] (0) 1   libxgboost.dylib                    0x0000000175dcba54 dmlc::LogMessageFatal::~LogMessageFatal() + 116\\n  [bt] (1) 2   libxgboost.dylib                    0x0000000175ea4c1a xgboost::metric::EvalEWiseBase<xgboost::metric::EvalRowRMSE>::Eval(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, bool) + 298\\n  [bt] (2) 3   libxgboost.dylib                    0x0000000175e7cc03 xgboost::LearnerImpl::EvalOneIter(int, std::__1::vector<std::__1::shared_ptr<xgboost::DMatrix>, std::__1::allocator<std::__1::shared_ptr<xgboost::DMatrix> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) + 2371\\n  [bt] (3) 4   libxgboost.dylib                    0x0000000175dd0792 XGBoosterEvalOneIter + 578\\n  [bt] (4) 5   libffi.8.dylib                      0x000000010a1b8d92 ffi_call_unix64 + 82\\n  [bt] (5) 6   ???                                 0x0000000315a245d0 0x0 + 13247858128\\n\\n')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/2f/cwgmhyzx4fn5cwp5j_dpmsd00000gn/T/ipykernel_22550/4276141754.py\", line 23, in xgb_objective\n",
      "    xgb_obj.fit(\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py\", line 82, in _train_internal\n",
      "    if callbacks.after_iteration(bst, i, dtrain, evals):\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/callback.py\", line 434, in after_iteration\n",
      "    score = model.eval_set(evals, epoch, self.metric)\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py\", line 1744, in eval_set\n",
      "    _check_call(_LIB.XGBoosterEvalOneIter(self.handle,\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [17:14:55] ../src/metric/elementwise_metric.cu:365: Check failed: preds.Size() == info.labels_.Size() (8721 vs. 2907) : label and prediction size not match, hint: use merror or mlogloss for multi-class classification\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000175dcba54 dmlc::LogMessageFatal::~LogMessageFatal() + 116\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x0000000175ea4c1a xgboost::metric::EvalEWiseBase<xgboost::metric::EvalRowRMSE>::Eval(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, bool) + 298\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x0000000175e7cc03 xgboost::LearnerImpl::EvalOneIter(int, std::__1::vector<std::__1::shared_ptr<xgboost::DMatrix>, std::__1::allocator<std::__1::shared_ptr<xgboost::DMatrix> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) + 2371\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x0000000175dd0792 XGBoosterEvalOneIter + 578\n",
      "  [bt] (4) 5   libffi.8.dylib                      0x000000010a1b8d92 ffi_call_unix64 + 82\n",
      "  [bt] (5) 6   ???                                 0x0000000315a245d0 0x0 + 13247858128\n",
      "\n",
      "\n",
      "\u001b[33m[W 2022-03-25 17:14:56,727]\u001b[0m Trial 4 failed because of the following error: XGBoostError('[17:14:55] ../src/metric/elementwise_metric.cu:365: Check failed: preds.Size() == info.labels_.Size() (8721 vs. 2907) : label and prediction size not match, hint: use merror or mlogloss for multi-class classification\\nStack trace:\\n  [bt] (0) 1   libxgboost.dylib                    0x0000000175dcba54 dmlc::LogMessageFatal::~LogMessageFatal() + 116\\n  [bt] (1) 2   libxgboost.dylib                    0x0000000175ea4c1a xgboost::metric::EvalEWiseBase<xgboost::metric::EvalRowRMSE>::Eval(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, bool) + 298\\n  [bt] (2) 3   libxgboost.dylib                    0x0000000175e7cc03 xgboost::LearnerImpl::EvalOneIter(int, std::__1::vector<std::__1::shared_ptr<xgboost::DMatrix>, std::__1::allocator<std::__1::shared_ptr<xgboost::DMatrix> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) + 2371\\n  [bt] (3) 4   libxgboost.dylib                    0x0000000175dd0792 XGBoosterEvalOneIter + 578\\n  [bt] (4) 5   libffi.8.dylib                      0x000000010a1b8d92 ffi_call_unix64 + 82\\n  [bt] (5) 6   ???                                 0x0000000313a1e5d0 0x0 + 13214279120\\n\\n')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/2f/cwgmhyzx4fn5cwp5j_dpmsd00000gn/T/ipykernel_22550/4276141754.py\", line 23, in xgb_objective\n",
      "    xgb_obj.fit(\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py\", line 82, in _train_internal\n",
      "    if callbacks.after_iteration(bst, i, dtrain, evals):\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/callback.py\", line 434, in after_iteration\n",
      "    score = model.eval_set(evals, epoch, self.metric)\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py\", line 1744, in eval_set\n",
      "    _check_call(_LIB.XGBoosterEvalOneIter(self.handle,\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [17:14:55] ../src/metric/elementwise_metric.cu:365: Check failed: preds.Size() == info.labels_.Size() (8721 vs. 2907) : label and prediction size not match, hint: use merror or mlogloss for multi-class classification\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000175dcba54 dmlc::LogMessageFatal::~LogMessageFatal() + 116\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x0000000175ea4c1a xgboost::metric::EvalEWiseBase<xgboost::metric::EvalRowRMSE>::Eval(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, bool) + 298\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x0000000175e7cc03 xgboost::LearnerImpl::EvalOneIter(int, std::__1::vector<std::__1::shared_ptr<xgboost::DMatrix>, std::__1::allocator<std::__1::shared_ptr<xgboost::DMatrix> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) + 2371\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x0000000175dd0792 XGBoosterEvalOneIter + 578\n",
      "  [bt] (4) 5   libffi.8.dylib                      0x000000010a1b8d92 ffi_call_unix64 + 82\n",
      "  [bt] (5) 6   ???                                 0x0000000313a1e5d0 0x0 + 13214279120\n",
      "\n",
      "\n",
      "\u001b[33m[W 2022-03-25 17:14:56,713]\u001b[0m Trial 5 failed because of the following error: XGBoostError('[17:14:55] ../src/metric/elementwise_metric.cu:365: Check failed: preds.Size() == info.labels_.Size() (8721 vs. 2907) : label and prediction size not match, hint: use merror or mlogloss for multi-class classification\\nStack trace:\\n  [bt] (0) 1   libxgboost.dylib                    0x0000000175dcba54 dmlc::LogMessageFatal::~LogMessageFatal() + 116\\n  [bt] (1) 2   libxgboost.dylib                    0x0000000175ea4c1a xgboost::metric::EvalEWiseBase<xgboost::metric::EvalRowRMSE>::Eval(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, bool) + 298\\n  [bt] (2) 3   libxgboost.dylib                    0x0000000175e7cc03 xgboost::LearnerImpl::EvalOneIter(int, std::__1::vector<std::__1::shared_ptr<xgboost::DMatrix>, std::__1::allocator<std::__1::shared_ptr<xgboost::DMatrix> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) + 2371\\n  [bt] (3) 4   libxgboost.dylib                    0x0000000175dd0792 XGBoosterEvalOneIter + 578\\n  [bt] (4) 5   libffi.8.dylib                      0x000000010a1b8d92 ffi_call_unix64 + 82\\n  [bt] (5) 6   ???                                 0x0000000314a215d0 0x0 + 13231068624\\n\\n')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/2f/cwgmhyzx4fn5cwp5j_dpmsd00000gn/T/ipykernel_22550/4276141754.py\", line 23, in xgb_objective\n",
      "    xgb_obj.fit(\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py\", line 82, in _train_internal\n",
      "    if callbacks.after_iteration(bst, i, dtrain, evals):\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/callback.py\", line 434, in after_iteration\n",
      "    score = model.eval_set(evals, epoch, self.metric)\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py\", line 1744, in eval_set\n",
      "    _check_call(_LIB.XGBoosterEvalOneIter(self.handle,\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [17:14:55] ../src/metric/elementwise_metric.cu:365: Check failed: preds.Size() == info.labels_.Size() (8721 vs. 2907) : label and prediction size not match, hint: use merror or mlogloss for multi-class classification\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000175dcba54 dmlc::LogMessageFatal::~LogMessageFatal() + 116\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x0000000175ea4c1a xgboost::metric::EvalEWiseBase<xgboost::metric::EvalRowRMSE>::Eval(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, bool) + 298\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x0000000175e7cc03 xgboost::LearnerImpl::EvalOneIter(int, std::__1::vector<std::__1::shared_ptr<xgboost::DMatrix>, std::__1::allocator<std::__1::shared_ptr<xgboost::DMatrix> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) + 2371\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x0000000175dd0792 XGBoosterEvalOneIter + 578\n",
      "  [bt] (4) 5   libffi.8.dylib                      0x000000010a1b8d92 ffi_call_unix64 + 82\n",
      "  [bt] (5) 6   ???                                 0x0000000314a215d0 0x0 + 13231068624\n",
      "\n",
      "\n",
      "\u001b[33m[W 2022-03-25 17:14:57,261]\u001b[0m Trial 1 failed because of the following error: XGBoostError('[17:14:57] ../src/metric/elementwise_metric.cu:365: Check failed: preds.Size() == info.labels_.Size() (8721 vs. 2907) : label and prediction size not match, hint: use merror or mlogloss for multi-class classification\\nStack trace:\\n  [bt] (0) 1   libxgboost.dylib                    0x0000000175dcba54 dmlc::LogMessageFatal::~LogMessageFatal() + 116\\n  [bt] (1) 2   libxgboost.dylib                    0x0000000175ea4c1a xgboost::metric::EvalEWiseBase<xgboost::metric::EvalRowRMSE>::Eval(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, bool) + 298\\n  [bt] (2) 3   libxgboost.dylib                    0x0000000175e7cc03 xgboost::LearnerImpl::EvalOneIter(int, std::__1::vector<std::__1::shared_ptr<xgboost::DMatrix>, std::__1::allocator<std::__1::shared_ptr<xgboost::DMatrix> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) + 2371\\n  [bt] (3) 4   libxgboost.dylib                    0x0000000175dd0792 XGBoosterEvalOneIter + 578\\n  [bt] (4) 5   libffi.8.dylib                      0x000000010a1b8d92 ffi_call_unix64 + 82\\n  [bt] (5) 6   ???                                 0x0000000310a155d0 0x0 + 13163910608\\n\\n')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/2f/cwgmhyzx4fn5cwp5j_dpmsd00000gn/T/ipykernel_22550/4276141754.py\", line 23, in xgb_objective\n",
      "    xgb_obj.fit(\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py\", line 82, in _train_internal\n",
      "    if callbacks.after_iteration(bst, i, dtrain, evals):\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/callback.py\", line 434, in after_iteration\n",
      "    score = model.eval_set(evals, epoch, self.metric)\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py\", line 1744, in eval_set\n",
      "    _check_call(_LIB.XGBoosterEvalOneIter(self.handle,\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [17:14:57] ../src/metric/elementwise_metric.cu:365: Check failed: preds.Size() == info.labels_.Size() (8721 vs. 2907) : label and prediction size not match, hint: use merror or mlogloss for multi-class classification\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000175dcba54 dmlc::LogMessageFatal::~LogMessageFatal() + 116\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x0000000175ea4c1a xgboost::metric::EvalEWiseBase<xgboost::metric::EvalRowRMSE>::Eval(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, bool) + 298\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x0000000175e7cc03 xgboost::LearnerImpl::EvalOneIter(int, std::__1::vector<std::__1::shared_ptr<xgboost::DMatrix>, std::__1::allocator<std::__1::shared_ptr<xgboost::DMatrix> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) + 2371\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x0000000175dd0792 XGBoosterEvalOneIter + 578\n",
      "  [bt] (4) 5   libffi.8.dylib                      0x000000010a1b8d92 ffi_call_unix64 + 82\n",
      "  [bt] (5) 6   ???                                 0x0000000310a155d0 0x0 + 13163910608\n",
      "\n",
      "\n",
      "\u001b[33m[W 2022-03-25 17:14:58,829]\u001b[0m Trial 3 failed because of the following error: XGBoostError('[17:14:58] ../src/metric/elementwise_metric.cu:365: Check failed: preds.Size() == info.labels_.Size() (8721 vs. 2907) : label and prediction size not match, hint: use merror or mlogloss for multi-class classification\\nStack trace:\\n  [bt] (0) 1   libxgboost.dylib                    0x0000000175dcba54 dmlc::LogMessageFatal::~LogMessageFatal() + 116\\n  [bt] (1) 2   libxgboost.dylib                    0x0000000175ea4c1a xgboost::metric::EvalEWiseBase<xgboost::metric::EvalRowRMSE>::Eval(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, bool) + 298\\n  [bt] (2) 3   libxgboost.dylib                    0x0000000175e7cc03 xgboost::LearnerImpl::EvalOneIter(int, std::__1::vector<std::__1::shared_ptr<xgboost::DMatrix>, std::__1::allocator<std::__1::shared_ptr<xgboost::DMatrix> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) + 2371\\n  [bt] (3) 4   libxgboost.dylib                    0x0000000175dd0792 XGBoosterEvalOneIter + 578\\n  [bt] (4) 5   libffi.8.dylib                      0x000000010a1b8d92 ffi_call_unix64 + 82\\n  [bt] (5) 6   ???                                 0x0000000312a1b5d0 0x0 + 13197489616\\n\\n')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/2f/cwgmhyzx4fn5cwp5j_dpmsd00000gn/T/ipykernel_22550/4276141754.py\", line 23, in xgb_objective\n",
      "    xgb_obj.fit(\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py\", line 82, in _train_internal\n",
      "    if callbacks.after_iteration(bst, i, dtrain, evals):\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/callback.py\", line 434, in after_iteration\n",
      "    score = model.eval_set(evals, epoch, self.metric)\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py\", line 1744, in eval_set\n",
      "    _check_call(_LIB.XGBoosterEvalOneIter(self.handle,\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [17:14:58] ../src/metric/elementwise_metric.cu:365: Check failed: preds.Size() == info.labels_.Size() (8721 vs. 2907) : label and prediction size not match, hint: use merror or mlogloss for multi-class classification\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000175dcba54 dmlc::LogMessageFatal::~LogMessageFatal() + 116\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x0000000175ea4c1a xgboost::metric::EvalEWiseBase<xgboost::metric::EvalRowRMSE>::Eval(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, bool) + 298\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x0000000175e7cc03 xgboost::LearnerImpl::EvalOneIter(int, std::__1::vector<std::__1::shared_ptr<xgboost::DMatrix>, std::__1::allocator<std::__1::shared_ptr<xgboost::DMatrix> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) + 2371\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x0000000175dd0792 XGBoosterEvalOneIter + 578\n",
      "  [bt] (4) 5   libffi.8.dylib                      0x000000010a1b8d92 ffi_call_unix64 + 82\n",
      "  [bt] (5) 6   ???                                 0x0000000312a1b5d0 0x0 + 13197489616\n",
      "\n",
      "\n",
      "\u001b[33m[W 2022-03-25 17:15:00,702]\u001b[0m Trial 7 failed because of the following error: XGBoostError('[17:15:00] ../src/metric/elementwise_metric.cu:365: Check failed: preds.Size() == info.labels_.Size() (8721 vs. 2907) : label and prediction size not match, hint: use merror or mlogloss for multi-class classification\\nStack trace:\\n  [bt] (0) 1   libxgboost.dylib                    0x0000000175dcba54 dmlc::LogMessageFatal::~LogMessageFatal() + 116\\n  [bt] (1) 2   libxgboost.dylib                    0x0000000175ea4c1a xgboost::metric::EvalEWiseBase<xgboost::metric::EvalRowRMSE>::Eval(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, bool) + 298\\n  [bt] (2) 3   libxgboost.dylib                    0x0000000175e7cc03 xgboost::LearnerImpl::EvalOneIter(int, std::__1::vector<std::__1::shared_ptr<xgboost::DMatrix>, std::__1::allocator<std::__1::shared_ptr<xgboost::DMatrix> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) + 2371\\n  [bt] (3) 4   libxgboost.dylib                    0x0000000175dd0792 XGBoosterEvalOneIter + 578\\n  [bt] (4) 5   libffi.8.dylib                      0x000000010a1b8d92 ffi_call_unix64 + 82\\n  [bt] (5) 6   ???                                 0x0000000316a275d0 0x0 + 13264647632\\n\\n')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/2f/cwgmhyzx4fn5cwp5j_dpmsd00000gn/T/ipykernel_22550/4276141754.py\", line 23, in xgb_objective\n",
      "    xgb_obj.fit(\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1250, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py\", line 188, in train\n",
      "    bst = _train_internal(params, dtrain,\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/training.py\", line 82, in _train_internal\n",
      "    if callbacks.after_iteration(bst, i, dtrain, evals):\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/callback.py\", line 434, in after_iteration\n",
      "    score = model.eval_set(evals, epoch, self.metric)\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py\", line 1744, in eval_set\n",
      "    _check_call(_LIB.XGBoosterEvalOneIter(self.handle,\n",
      "  File \"/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [17:15:00] ../src/metric/elementwise_metric.cu:365: Check failed: preds.Size() == info.labels_.Size() (8721 vs. 2907) : label and prediction size not match, hint: use merror or mlogloss for multi-class classification\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000175dcba54 dmlc::LogMessageFatal::~LogMessageFatal() + 116\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x0000000175ea4c1a xgboost::metric::EvalEWiseBase<xgboost::metric::EvalRowRMSE>::Eval(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, bool) + 298\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x0000000175e7cc03 xgboost::LearnerImpl::EvalOneIter(int, std::__1::vector<std::__1::shared_ptr<xgboost::DMatrix>, std::__1::allocator<std::__1::shared_ptr<xgboost::DMatrix> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) + 2371\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x0000000175dd0792 XGBoosterEvalOneIter + 578\n",
      "  [bt] (4) 5   libffi.8.dylib                      0x000000010a1b8d92 ffi_call_unix64 + 82\n",
      "  [bt] (5) 6   ???                                 0x0000000316a275d0 0x0 + 13264647632\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_base_params = {\n",
    "    'objective' : 'multi:softprob', \n",
    "    'learning_rate' : 0.1,\n",
    "    'verbosity' : 0,\n",
    "    'n_jobs' : -1,\n",
    "    'random_state' : p.RANDOM_STATE,\n",
    "    }\n",
    "\n",
    "def xgb_objective(trial, X_train = X_train, y_train = y_train, X_test = X_test, y_test = y_test, base_params = xgb_base_params):\n",
    "\n",
    "    obj_params = {\n",
    "        'max_depth' : trial.suggest_int('max_depth', 2, 7),\n",
    "        'min_child_weight' : trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'n_estimators' : trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'subsample' : trial.suggest_float('subsample', 0.1, 1),\n",
    "\n",
    "        **base_params\n",
    "        }\n",
    "\n",
    "    pruning_callback = XGBoostPruningCallback(trial, observation_key = 'validation_1-rmse')\n",
    "\n",
    "    xgb_obj = XGBClassifier(**obj_params)\n",
    "    xgb_obj.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_metric = 'auc',\n",
    "        eval_set = [(X_train, y_train), (X_test, y_test)],\n",
    "        early_stopping_rounds = obj_params['n_estimators'] * 0.1,\n",
    "        verbose = 0,\n",
    "        callbacks = [pruning_callback]\n",
    "        )\n",
    "\n",
    "    y_pred = xgb_obj.predict_proba(X_test)\n",
    "\n",
    "    roc = roc_auc_score(y_true=y_test, y_score=y_pred, multi_class='ovr')\n",
    "    \n",
    "    return roc\n",
    "\n",
    "xgb_study = optuna.create_study(direction = 'maximize')\n",
    "xgb_study.optimize(xgb_objective, n_trials = 200, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_tuned_params = {**xgb_study.best_params, **xgb_base_params}\n",
    "xgb_tuned_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_tuned = XGBClassifier(**xgb_tuned_params)\n",
    "xgb_tuned.fit(\n",
    "    **train_data,\n",
    "    eval_metric = 'auc',\n",
    "    eval_set = [(X_train, y_train), (X_test, y_test)],\n",
    "    early_stopping_rounds = xgb_tuned_params['n_estimators'] * 0.1,\n",
    "    verbose = 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACRO\n",
      "Accuracy:\t 0.7206185567010309\n",
      "Precision:\t 0.702044044044044\n",
      "Recall:\t\t 0.575268008506645\n",
      "F1 score:\t 0.6060845944585984\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.38      0.48       121\n",
      "           1       0.72      0.94      0.82       576\n",
      "           2       0.74      0.40      0.52       273\n",
      "\n",
      "    accuracy                           0.72       970\n",
      "   macro avg       0.70      0.58      0.61       970\n",
      "weighted avg       0.72      0.72      0.69       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(xgb_tuned, **test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_objective(trial, X_train = X_train, y_train = y_train, X_test = X_test, y_test = y_test):\n",
    "\n",
    "    obj_params = {\n",
    "        'alpha' : trial.suggest_uniform('alpha', 0.2, 2),\n",
    "        'fit_prior' : trial.suggest_categorical('fit_prior', [True, False])\n",
    "    }\n",
    "\n",
    "    nb_obj = MultinomialNB(**obj_params)\n",
    "    nb_obj.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = nb_obj.predict_proba(X_test)\n",
    "\n",
    "    roc = roc_auc_score(y_true = y_test, y_pred = y_pred, average = 'macro', multi_class='ovr')\n",
    "    \n",
    "    return roc\n",
    "\n",
    "nb_study = optuna.create_study(direction='maximize')\n",
    "nb_study.optimize(nb_objective, n_trials = 200, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_tuned_params = nb_study.best_params.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-tuned Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACRO\n",
      "Accuracy:\t 0.7058823529411765\n",
      "Precision:\t 0.6759885039511749\n",
      "Recall:\t\t 0.5425576509299771\n",
      "F1 score:\t 0.5704572342069808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.31      0.43       121\n",
      "           1       0.72      0.95      0.82       576\n",
      "           2       0.64      0.36      0.46       272\n",
      "\n",
      "    accuracy                           0.71       969\n",
      "   macro avg       0.68      0.54      0.57       969\n",
      "weighted avg       0.69      0.71      0.67       969\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(rf, **val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = {x : y for x, y in zip(rf.feature_names_in_, rf.feature_importances_)}"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c31da5edd4aad8fb53d12d73a780cc43060c0f39f08ff1fc327c1bcdbfa7e83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('data_analytics')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
