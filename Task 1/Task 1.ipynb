{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction\n",
    "### code from `data_loader_demo.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "annoying-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Use HuggingFace's datasets library to access the financial_phrasebank dataset\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Exploration\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Feature Engineering\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Modelling\n",
    "import params as p\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f4a2e7-8a1f-4fed-a323-1b82d7080e03",
   "metadata": {},
   "source": [
    "# Financial Phrasebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8502fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset financial_phrasebank (/Users/jamesstephenson/.cache/huggingface/datasets/financial_phrasebank/sentences_50agree/1.0.0/a6d468761d4e0c8ae215c77367e1092bead39deb08fbf4bffd7c0a6991febbf0)\n",
      "100%|██████████| 1/1 [00:00<00:00, 72.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is a dictionary with two splits: \n",
      "\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label'],\n",
      "        num_rows: 4846\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# The financial_phrasebank dataset is available in four variations. It has no predefined train/validation/test splits.\n",
    "# Each data point was annotated by 5-8 people, then their annotations were combined. \n",
    "# Each variation of the dataset contains examples with different levels of agreement. \n",
    "# Let's use the one containing all data points where at least 50% of the annotators agreed on the label.\n",
    "dataset = load_dataset(\n",
    "    \"financial_phrasebank\", \n",
    "    'sentences_50agree' # Select variation of the dataset\n",
    ")\n",
    "\n",
    "print(f'The dataset is a dictionary with two splits: \\n\\n{dataset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca009bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split test data from training data\n",
    "train_sentences, test_sentences, train_labels, test_labels = train_test_split(\n",
    "    dataset[\"train\"]['sentence'], \n",
    "    dataset[\"train\"]['label'], \n",
    "    test_size=0.2, \n",
    "    stratify=dataset[\"train\"]['label']  # make sure the same proportion of labels is in the test set and training set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b3af369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many instances in the train dataset? \n",
      "\n",
      "3876\n",
      "\n",
      "What does one instance look like? \n",
      "\n",
      "The platform would continue to be the development framework for Symbian and MeeGo .\n"
     ]
    }
   ],
   "source": [
    "# label 0 = negative, 1 = neutral, 2 = positive\n",
    "print(f'How many instances in the train dataset? \\n\\n{len(train_sentences)}')\n",
    "print('')\n",
    "print(f'What does one instance look like? \\n\\n{train_sentences[234]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58ea906-8488-43a9-90dd-94695d700d19",
   "metadata": {},
   "source": [
    "It may also be necessary to create a _validation_ set (also called 'development' set or 'devset'). The validation set can be used to compute performance of your model when tuning hyperparameters,  optimising combinations of features, or looking at the errors your model makes before improving it. This allows you to hold out the test set to give a fair evaluation of the model and how well it generalises to new examples. This avoids tuning the model to specifso it gets good performance on the test set examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c873dbe-b6a6-41ed-9f03-b52a5e0a85c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_sentences, train_labels, test_size=0.25, stratify=train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57d10fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many instances in the validation dataset? \n",
      "\n",
      "969\n",
      "\n",
      "How many instances in the test dataset? \n",
      "\n",
      "970\n"
     ]
    }
   ],
   "source": [
    "print(f'How many instances in the validation dataset? \\n\\n{len(val_sentences)}\\n')\n",
    "print(f'How many instances in the test dataset? \\n\\n{len(test_sentences)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame({'sentences' : train_sentences, 'labels' : train_labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Very Brief Response Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should only need to do this for train due to random split. So would expect to see the same structure for test and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (15, 8))\n",
    "\n",
    "ax = train.labels.value_counts().plot(kind='bar', title = 'Label Counts')\n",
    "\n",
    "ax.set_xlabel(\"Labels\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "plt.xticks(rotation = 0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slight Imbalance of labels, but nothing that will be an issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featuring Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove some stopwords to capture negation in n-grams if possible\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words.remove('no')\n",
    "stop_words.remove('not')\n",
    "stop_words.remove('but')\n",
    "\n",
    "# load up a simple porter stemmer - nothing fancy\n",
    "ps = nltk.porter.PorterStemmer()\n",
    "\n",
    "def simple_text_preprocessor(document): \n",
    "    # lower case\n",
    "    document = str(document).lower()\n",
    "    \n",
    "    # remove unnecessary characters\n",
    "    document = re.sub(r'[^a-zA-Z]',r' ', document)\n",
    "    document = re.sub(r'nbsp', r'', document)\n",
    "    document = re.sub(' +', ' ', document)\n",
    "    \n",
    "    # simple porter stemming\n",
    "    document = ' '.join([ps.stem(word) for word in document.split()])\n",
    "    \n",
    "    # stopwords removal\n",
    "    document = ' '.join([word for word in document.split() if word not in stop_words])\n",
    "    \n",
    "    return document\n",
    "\n",
    "stp = np.vectorize(simple_text_preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_sentences = stp(train_sentences)\n",
    "clean_test_sentences = stp(test_sentences)\n",
    "clean_val_sentences = stp(val_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df = 0.0, max_df = 1.0, ngram_range = (1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tfidf.fit_transform(clean_train_sentences).toarray()\n",
    "X_train = pd.DataFrame(X_train, columns = tfidf.get_feature_names_out())\n",
    "\n",
    "X_test = tfidf.transform(clean_test_sentences).toarray()\n",
    "X_test = pd.DataFrame(X_test, columns = tfidf.get_feature_names_out())\n",
    "\n",
    "X_val = tfidf.transform(clean_val_sentences).toarray()\n",
    "X_val = pd.DataFrame(X_val, columns = tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aalborg</th>\n",
       "      <th>aalborg northern</th>\n",
       "      <th>aaltonen</th>\n",
       "      <th>aaltonen finland</th>\n",
       "      <th>aava</th>\n",
       "      <th>aava mobil</th>\n",
       "      <th>aazhang</th>\n",
       "      <th>aazhang behnaam</th>\n",
       "      <th>ab</th>\n",
       "      <th>ab finnish</th>\n",
       "      <th>...</th>\n",
       "      <th>zinc mine</th>\n",
       "      <th>zinc stream</th>\n",
       "      <th>zip</th>\n",
       "      <th>zip expert</th>\n",
       "      <th>zone</th>\n",
       "      <th>zone neudorf</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoo poland</th>\n",
       "      <th>zte</th>\n",
       "      <th>zte corp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28990 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aalborg  aalborg northern  aaltonen  aaltonen finland  aava  aava mobil  \\\n",
       "0      0.0               0.0       0.0               0.0   0.0         0.0   \n",
       "1      0.0               0.0       0.0               0.0   0.0         0.0   \n",
       "2      0.0               0.0       0.0               0.0   0.0         0.0   \n",
       "3      0.0               0.0       0.0               0.0   0.0         0.0   \n",
       "4      0.0               0.0       0.0               0.0   0.0         0.0   \n",
       "\n",
       "   aazhang  aazhang behnaam   ab  ab finnish  ...  zinc mine  zinc stream  \\\n",
       "0      0.0              0.0  0.0         0.0  ...        0.0          0.0   \n",
       "1      0.0              0.0  0.0         0.0  ...        0.0          0.0   \n",
       "2      0.0              0.0  0.0         0.0  ...        0.0          0.0   \n",
       "3      0.0              0.0  0.0         0.0  ...        0.0          0.0   \n",
       "4      0.0              0.0  0.0         0.0  ...        0.0          0.0   \n",
       "\n",
       "   zip  zip expert  zone  zone neudorf  zoo  zoo poland  zte  zte corp  \n",
       "0  0.0         0.0   0.0           0.0  0.0         0.0  0.0       0.0  \n",
       "1  0.0         0.0   0.0           0.0  0.0         0.0  0.0       0.0  \n",
       "2  0.0         0.0   0.0           0.0  0.0         0.0  0.0       0.0  \n",
       "3  0.0         0.0   0.0           0.0  0.0         0.0  0.0       0.0  \n",
       "4  0.0         0.0   0.0           0.0  0.0         0.0  0.0       0.0  \n",
       "\n",
       "[5 rows x 28990 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_labels\n",
    "y_test = test_labels\n",
    "y_val = val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    print('MACRO')\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    print(f'Accuracy:\\t {acc}')\n",
    "\n",
    "    prec = precision_score(y, y_pred, average='macro')\n",
    "    print(f'Precision:\\t {prec}')\n",
    "\n",
    "    rec = recall_score(y, y_pred, average='macro')\n",
    "    print(f'Recall:\\t\\t {rec}')\n",
    "\n",
    "    f1 = f1_score(y, y_pred, average='macro')\n",
    "    print(f'F1 score:\\t {f1}')\n",
    "\n",
    "    # We can get all of these with a per-class breakdown using classification_report:\n",
    "    print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = {'X' : X_test, 'y' : y_test}\n",
    "val_data = {'X' : X_val, 'y' : y_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACRO\n",
      "Accuracy:\t 0.668041237113402\n",
      "Precision:\t 0.6543181826329809\n",
      "Recall:\t\t 0.4327683049273958\n",
      "F1 score:\t 0.4191596681743343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.04      0.08       121\n",
      "           1       0.67      0.99      0.80       576\n",
      "           2       0.67      0.27      0.38       273\n",
      "\n",
      "    accuracy                           0.67       970\n",
      "   macro avg       0.65      0.43      0.42       970\n",
      "weighted avg       0.66      0.67      0.59       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(nb, **test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=73)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=p.RANDOM_STATE)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACRO\n",
      "Accuracy:\t 0.7371134020618557\n",
      "Precision:\t 0.7248473748473749\n",
      "Recall:\t\t 0.5727936310322673\n",
      "F1 score:\t 0.6060171065162577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.29      0.41       121\n",
      "           1       0.74      0.96      0.84       576\n",
      "           2       0.72      0.47      0.57       273\n",
      "\n",
      "    accuracy                           0.74       970\n",
      "   macro avg       0.72      0.57      0.61       970\n",
      "weighted avg       0.73      0.74      0.71       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(rf, **test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-tuned Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACRO\n",
      "Accuracy:\t 0.6780185758513931\n",
      "Precision:\t 0.7808237319560324\n",
      "Recall:\t\t 0.4537124250526657\n",
      "F1 score:\t 0.4540828161977169\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.08      0.15       121\n",
      "           1       0.68      0.98      0.80       576\n",
      "           2       0.67      0.29      0.41       272\n",
      "\n",
      "    accuracy                           0.68       969\n",
      "   macro avg       0.78      0.45      0.45       969\n",
      "weighted avg       0.71      0.68      0.61       969\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(nb, **val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACRO\n",
      "Accuracy:\t 0.7337461300309598\n",
      "Precision:\t 0.7488392429869638\n",
      "Recall:\t\t 0.5834678109076505\n",
      "F1 score:\t 0.6224852833942897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.34      0.48       121\n",
      "           1       0.74      0.94      0.83       576\n",
      "           2       0.71      0.47      0.57       272\n",
      "\n",
      "    accuracy                           0.73       969\n",
      "   macro avg       0.75      0.58      0.62       969\n",
      "weighted avg       0.74      0.73      0.71       969\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(rf, **val_data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c31da5edd4aad8fb53d12d73a780cc43060c0f39f08ff1fc327c1bcdbfa7e83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('data_analytics')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
